{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4, Part 2\n",
    "\n",
    "1. Start by normalizing the data and separating a validation set with 20\\% of the data randomly selected. The remaining 80\\% will be called the sub-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "import ForwardSelection\n",
    "import ROCAnalysis\n",
    "import MachineLearningModel\n",
    "\n",
    "importlib.reload(ForwardSelection)\n",
    "importlib.reload(ROCAnalysis)\n",
    "importlib.reload(MachineLearningModel)\n",
    "\n",
    "from ForwardSelection import ForwardSelection\n",
    "from ROCAnalysis import ROCAnalysis\n",
    "from MachineLearningModel import LogisticRegression\n",
    "\n",
    "# Load the data\n",
    "data = np.genfromtxt('./resources/datasets/heart_disease_cleveland.csv', delimiter=',', skip_header=1) \n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "model = LogisticRegression()\n",
    "X_normalized = model.normalize(X)\n",
    "\n",
    "seed = 14159\n",
    "np.random.seed(seed)\n",
    "indices = np.random.permutation(len(X_normalized))\n",
    "split_point = int(0.8 * len(X_normalized))\n",
    "\n",
    "X_subdataset = X_normalized[indices[:split_point]]\n",
    "y_subdataset = y[indices[:split_point]]\n",
    "X_validation = X_normalized[indices[split_point:]]\n",
    "y_validation = y[indices[split_point:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use your implementation of forward selection to estimate a reasonable classification model. You must use your implementation of Logistic Regression in this assignment. The decision to make a reasonable number of iterations and learning rate is up to you but must be justified. Optimize the model selection to produce the best f-score. You must use the sub-dataset in your forward selection process. Report the features selected by this process and discuss your results. \n",
    "\n",
    "--- Your answer here --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current features: []. Best feature to add: 2 with F-score: 0.795\n",
      "Current features: [2]. Best feature to add: 6 with F-score: 0.797\n",
      "Current features: [2, 6]. Best feature to add: 3 with F-score: 0.811\n",
      "Current features: [2, 6, 3]. Best feature to add: 0 with F-score: 0.811\n",
      "Current features: [2, 6, 3, 0]. Best feature to add: 1 with F-score: 0.820\n",
      "Current features: [2, 6, 3, 0, 1]. Best feature to add: 10 with F-score: 0.827\n",
      "Current features: [2, 6, 3, 0, 1, 10]. Best feature to add: 11 with F-score: 0.860\n",
      "Current features: [2, 6, 3, 0, 1, 10, 11]. Best feature to add: 4 with F-score: 0.860\n",
      "Current features: [2, 6, 3, 0, 1, 10, 11, 4]. Best feature to add: 5 with F-score: 0.860\n",
      "Current features: [2, 6, 3, 0, 1, 10, 11, 4, 5]. Best feature to add: 12 with F-score: 0.860\n",
      "Current features: [2, 6, 3, 0, 1, 10, 11, 4, 5, 12]. Best feature to add: 7 with F-score: 0.853\n",
      "Current features: [2, 6, 3, 0, 1, 10, 11, 4, 5, 12, 7]. Best feature to add: 8 with F-score: 0.785\n",
      "Current features: [2, 6, 3, 0, 1, 10, 11, 4, 5, 12, 7, 8]. Best feature to add: 9 with F-score: 0.785\n",
      "\n",
      "Selected features: [2, 6, 3, 0, 1, 10, 11]\n",
      "Best F-score: 0.860\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(learning_rate=0.01, num_iterations=1000)\n",
    "\n",
    "forward_selection = ForwardSelection(X_subdataset, y_subdataset, model, seed)\n",
    "forward_selection.forward_selection()\n",
    "selected_features = forward_selection.selected_features\n",
    "best_fscore = forward_selection.best_cost\n",
    "\n",
    "# Report the selected features and the best F-score\n",
    "print(\"\\nSelected features:\", selected_features)\n",
    "print(f\"Best F-score: {best_fscore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Report the performance of the best model in the validation set regarding all statistics available in your ROCAnalysis class. \n",
    "Was the process successful when compared to using all features?  \n",
    "Discuss your results regarding these metrics and what you can conclude from this experiment.\n",
    "\n",
    "Discussion:  \n",
    "The forward selection process selected a subset of features that resulted in a model with a precision of 0.719, recall of 0.731, and an F1 score of 0.725. These metrics indicate that the model has a good performance in identifying true positives with a balanced trade-off between precision and recall.\n",
    "\n",
    "However, when compared to the model using all features, the selected subset of features resulted in lower performance metrics. The model using all features achieved a precision of 0.809, recall of 0.846, and an F1 score of 0.827. This suggests that the additional features not selected by the forward selection process contribute valuable information that improves the model's ability to correctly classify the target variable.\n",
    "\n",
    "In conclusion, while the forward selection process was able to identify a subset of features that produced a well-performing model, the use of all features resulted in a better-performing model. This indicates that, in this case, the additional features provide important information that enhances the model's performance. Therefore, it may be beneficial to consider using all available features or exploring other feature selection methods to achieve the best possible model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using forward selection:\n",
      "Precision: 0.719\n",
      "Recall (TP Rate): 0.731\n",
      "False Positive Rate: 0.286\n",
      "F1 Score: 0.725\n",
      "\n",
      "Performance using all features:\n",
      "Precision: 0.809\n",
      "Recall (TP Rate): 0.846\n",
      "False Positive Rate: 0.200\n",
      "F1 Score: 0.827\n"
     ]
    }
   ],
   "source": [
    "X_validation_selected = X_validation[:, selected_features]\n",
    "\n",
    "y_pred = model.predict(X_validation_selected)\n",
    "y_validation_normalized = (y_validation >= 0.5).astype(int)\n",
    "y_pred_normalized = (y_pred >= 0.5).astype(int)\n",
    "roc_analysis = ROCAnalysis(y_validation_normalized, y_pred_normalized)\n",
    "\n",
    "print(\"Performance using forward selection:\")\n",
    "print(\"Precision:\", f\"{roc_analysis.precision():.3f}\")\n",
    "print(\"Recall (TP Rate):\", f\"{roc_analysis.tp_rate():.3f}\")\n",
    "print(\"False Positive Rate:\", f\"{roc_analysis.fp_rate():.3f}\")\n",
    "print(\"F1 Score:\", f\"{roc_analysis.f_score():.3f}\")\n",
    "\n",
    "model_all = LogisticRegression(learning_rate=0.01, num_iterations=1000)\n",
    "model_all.fit(X_normalized, y)\n",
    "y_pred = model_all.predict(X_validation)\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "roc_analysis_all_features = ROCAnalysis(y_validation, y_pred)\n",
    "\n",
    "print(\"\\nPerformance using all features:\")\n",
    "print(\"Precision:\", f\"{roc_analysis_all_features.precision():.3f}\")\n",
    "print(\"Recall (TP Rate):\", f\"{roc_analysis_all_features.tp_rate():.3f}\")\n",
    "print(\"False Positive Rate:\", f\"{roc_analysis_all_features.fp_rate():.3f}\")\n",
    "print(\"F1 Score:\", f\"{roc_analysis_all_features.f_score():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2DV516",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
